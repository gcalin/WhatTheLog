"""
Author: Thomas Werthenbach
Email: t.a.k.werthenbach@student.tudelft.nl
"""

import multiprocessing
import os
import random
import shutil
from copy import deepcopy
from typing import List, Dict, Tuple

import numpy as np

from scripts.log_scrambler import produce_false_trace
from whatthelog.prefixtree.edge_properties import EdgeProperties
from whatthelog.prefixtree.graph import Graph
from whatthelog.prefixtree.prefix_tree_factory import PrefixTreeFactory
from whatthelog.prefixtree.state import State
from whatthelog.syntaxtree.syntax_tree import SyntaxTree
from whatthelog.syntaxtree.syntax_tree_factory import SyntaxTreeFactory

random.seed(os.environ['random_seed'] if 'random_seed' in os.environ else 5)


class MarkovChain:
    """
    This class is used compress a model generated by log statements by using a Markov chain.
    """

    def __init__(self, traces_dir: str, config_file: str = "resources/config.json", weight_size: float = 0.5,
                 weight_accuracy: float = 0.5, eval_file: str = None, false_dir: str = 'out/false_traces/',
                 true_dir: str = 'resources/true_traces/', true_test_dir: str = 'out/true_traces/'):
        self.maxLength = 0
        self.traces_dir = traces_dir
        self.config_file = config_file
        self.false_dir = false_dir
        self.true_dir = true_dir
        self.true_test_dir = true_test_dir

        self.eval_file = eval_file
        if eval_file:
            with open(eval_file, 'w+') as open_file:
                open_file.write('')

        self.weight_size = weight_size
        self.weight_accuracy = weight_accuracy

        # Parse the syntax_tree from the config file.
        self.syntax_tree: SyntaxTree = SyntaxTreeFactory().parse_file(self.config_file)
        all_states: List[str] = self.get_all_states(self.syntax_tree)
        self.pt = None

        # Give every state an id.
        self.states: Dict[str, int] = dict()
        self.states['root'] = 0
        self.states['terminal'] = 1
        for a in range(len(all_states)):
            if all_states[a] in self.states:
                raise Exception(all_states[a])
            self.states[all_states[a]] = a + 2

        # Initialize the transition matrix for the root and terminal node.
        self.transitionMatrix = [[0 for _ in range(len(self.states))]
                                 for _ in range(len(self.states))]

        self.initial_size = len(self.transitionMatrix)

        print('[ markov.py ] - Chain ready.')

    def generate_false_traces_from_prefix_tree(self, amount: int = 50) -> None:
        """
        This method will generate negative/false traces on a pre-specified location.
        It will also initialize a prefix tree.
        :param amount: Specifies the amount of negative/false traces to produce
        """
        self.pt = PrefixTreeFactory.get_prefix_tree(self.traces_dir, self.config_file)
        print('[ markov.py ] - Generating false traces...')
        self.generate_false_traces(amount)
        print('[ markov.py ] - False traces generated')

    def generate_false_traces(self, amount: int = 50) -> None:
        """
        This method will generate negative/false traces on a pre-specified location.
        :param amount: Specifies the amount of negative/false traces to produce
        """
        for i in range(amount):
            produce_false_trace(os.path.join(self.traces_dir, os.listdir(self.traces_dir)
                                [random.randint(0, len(os.listdir(self.traces_dir)) - 1)]),
                                self.false_dir + '/false' + str(i), self.syntax_tree, self.pt)

    def get_all_states(self, syntax_tree: SyntaxTree) -> List[str]:
        """
        This method retrieves all the states from a SyntaxTree.
        :param syntax_tree: Specifies the tree of which the states should be retrieved.
        """
        res = []
        if len(syntax_tree.get_children()) > 0:
            for c in syntax_tree.get_children():
                res += self.get_all_states(c)
        else:
            return [syntax_tree.name]
        return res

    def remove(self, new: int, to_delete: int, matrix=None, states=None) -> None:
        """
        Removes a specific state from the transition matrix. It merges the probabilities into another state.
        :param new: The state in which the to-be-deleted state will be merged.
        :param to_delete: The state which will be removed. Its probabilities will be merged into 'new'.
        :param matrix: Specifies the transition matrix from which to remove the states.
        :param states: Specifies the states dictionary which should be modified.
        """
        if new == to_delete:
            raise Exception('trying to delete self')

        if matrix is None:
            matrix = self.transitionMatrix
        if states is None:
            states = self.states

        for i in range(len(matrix)):
            matrix[new][i] += matrix[to_delete][i]
            matrix[new][i] /= 2  # Normalize again

        del matrix[to_delete]

        for key in states.copy():
            if states[key] == to_delete:
                states[key] = new
            elif states[key] > to_delete:
                states[key] -= 1

        for arr in matrix:
            arr[new] += arr[to_delete]
            del arr[to_delete]

    def parallel(self, files: List[str]) -> List[List[float]]:
        """
        This method is used for parallel training of the transition matrix.
        :param files: Specifies the files this process should train the matrix on.
        """
        for file in files:
            with open(self.traces_dir + file, 'r') as open_file:
                current = 'root'
                for line in open_file.readlines():
                    try:
                        next_node = self.syntax_tree.search(line).name
                    except AttributeError as e:
                        print(line)
                        raise e
                    if next_node not in self.states:
                        raise Exception('Node not found in self.states')
                    self.transitionMatrix[self.states[current]][self.states[next_node]] += 1
                    current = next_node
                self.transitionMatrix[self.states[current]][self.states['terminal']] += 1
        return self.transitionMatrix

    def delete_unreachable(self) -> None:
        """
        Removes any unreachable states from the transition matrix as a form of initial compression.
        """
        to_delete: List[int] = list()
        for c in range(len(self.transitionMatrix)):
            if c > 0:  # the root state is an exception
                s = 0
                for r in self.transitionMatrix:
                    s += r[c]
                if s == 0:
                    to_delete.append(c)

        to_delete.sort(reverse=True)
        for d in to_delete:
            for key in self.states.copy():
                if self.states[key] == d:
                    del self.states[key]
                elif self.states[key] > d:
                    self.states[key] -= 1
            del self.transitionMatrix[d]
            for r in self.transitionMatrix:
                del r[d]

    def train(self) -> None:
        """
        Trains the probabilities of the transition matrix based on a pre-specified set of log files.
        """
        print('[ markov.py ] - Start training using multiprocessing...')

        a_pool = multiprocessing.Pool()
        matrix = None
        for result in a_pool.map(self.parallel, np.array_split(os.listdir(self.traces_dir), 12)):
            if matrix is None:
                matrix = result
            else:
                for r in range(len(result)):
                    for c in range(len(result)):
                        matrix[r][c] += result[r][c]
        a_pool.close()
        a_pool.join()
        self.transitionMatrix = matrix
        print('[ markov.py ] - Training done.')

        print('[ markov.py ] - Start Normalizing...')
        for i in range(len(self.transitionMatrix)):
            row = self.transitionMatrix[i]
            s = sum(row)
            if s > 0:
                for a in range(len(row)):
                    self.transitionMatrix[i][a] /= s
        print('[ markov.py ] - Normalizing done.')

        # Delete the unreachable states
        self.delete_unreachable()

        self.initial_size = len(self.transitionMatrix)

        self.transitionMatrix[1][1] = 1  # Create a self loop for the terminal state

    def find_duplicates(self, threshold: float = 0.0, row_duplicates: bool = True) -> List[List[int]]:
        """
        This method searches for either duplicate rows or columns, based on the value of 'row_duplicates'.
        :param threshold: This value indicates the maximum offset of two rows in order to be considered 'equivalent'.
        :param row_duplicates: Indicates whether we are looking for row duplicates or column duplicates.
        """
        result = list()

        for row in range(len(self.transitionMatrix)):
            to_append = [row]
            for i in range(len(self.transitionMatrix)):
                if row != i:

                    # Check if we have not already selected this row as candidate
                    found = False
                    for a in result:
                        if i in a:
                            found = True
                            break
                    if not found:
                        equivalent = True
                        for pos in range(len(self.transitionMatrix[i])):
                            if (row_duplicates and
                                abs(self.transitionMatrix[i][pos] - self.transitionMatrix[row][pos]) > threshold) \
                                    or \
                                    (not row_duplicates and
                                     abs(self.transitionMatrix[pos][i] - self.transitionMatrix[pos][row]) > threshold):
                                equivalent = False
                                break
                        if equivalent:
                            to_append.append(i)
            if len(to_append) > 1:
                result.append(to_append)

        return result

    def find_prop_1(self, threshold: float = 0.0) -> List[List[int]]:
        """
        Searches for entries in the transition matrix which have a probability of 1 of going to a certain state.
        :param threshold: indicates the amount of which a value is allowed to diverge from 1 in order to be considered.
        """
        temporary_result = list()

        for r in range(len(self.transitionMatrix)):
            for d in range(len(self.transitionMatrix)):
                # We don't want to remove the root and terminal node
                if self.transitionMatrix[r][d] >= 1.0 - threshold and r != d:
                    temporary_result.append([r, d])  # Only one, otherwise things might break
                    break

        result = list()
        for i in temporary_result:
            new = True
            for r in result:
                if r[-1] == i[0] and i[1] not in r:
                    r.append(i[1])
                    new = False
                    break
            if new:
                result.append(i)

        return result

    def build_graph(self) -> Graph:
        """
        Builds a Graph object based on the current states dictionary and transition matrix.
        """
        graph_nodes = dict()
        graph_nodes[0] = State(['root'])
        graph = Graph(graph_nodes[0])
        graph.add_state(graph_nodes[0])
        for k, v in self.states.items():
            if k != 'root':
                graph_nodes[v] = State([k])
                graph.add_state(graph_nodes[v])

        for r in range(len(self.transitionMatrix)):
            for c in range(len(self.transitionMatrix)):
                if self.transitionMatrix[r][c] > 0:
                    graph.add_edge(graph_nodes[r], graph_nodes[c], EdgeProperties([]))
        return graph

    def process_candidate_list(self, candidate: List[int], matrix=None, states=None) -> None:
        """
        Merges the states of a candidate for compression.
        :param candidate: The list of states to be merged, also known as the current candidate.
        :param matrix: The transition matrix on which the candidate should be applied.
        :param states: The states dictionary on which the candidate should be applied.
        """
        current = candidate.pop(0)
        while len(candidate) > 0:
            next_node = candidate.pop(0)
            self.remove(current, next_node, matrix, states)
            for a in range(len(candidate)):
                candidate[a] -= 1

    def evaluate_candidate(self, candidate: List[int]) -> float:
        """
        Evaluates the score of a candidate. This score is based on conciseness and accuracy.
        :param candidate: The candidate which should be evaluated
        """
        if self.weight_size * len(candidate) / self.maxLength + self.weight_accuracy < self.weight_size:
            # Optimal accuracy for this candidate vs the worst accuracy for the candidate with most compression
            return 0
        else:
            matrix = deepcopy(self.transitionMatrix)
            states = deepcopy(self.states)
            current_length = len(candidate)
            self.process_candidate_list(candidate, matrix, states)
            return self.weight_size * current_length / self.maxLength + self.weight_accuracy * \
                np.mean(self.calculate_accuracy(matrix, states))

    def calculate_accuracy(self, matrix: List[List[float]] = None, states: Dict[str, int] = None) \
            -> Tuple[float, float, float]:
        """
        Evaluates the specificity, recall and precision of a transition matrix.
        Specificity is calculated as: true negatives / (true negatives + false positives)
        Recall is calculated as:      true positives / (true positives + false negatives)
        Precision is calculated as:   true positives / (true positives + false positives)
        :param matrix: The transition matrix which should be evaluated.
        :param states: The states dictionary which should be evaluated.
        """
        if matrix is None:
            matrix = self.transitionMatrix
        if states is None:
            states = self.states

        true_negative = 0
        for file in os.listdir(self.false_dir):
            with open(os.path.join(self.false_dir, file), 'r') as open_file:
                current = states['root']
                for line in open_file.readlines():
                    next_node = states[self.syntax_tree.search(line).name]
                    if matrix[current][next_node] < 1 / 1e10:  # Some small value close to 0
                        true_negative += 1
                        break
                    current = next_node

        true_positive = 0
        for file in os.listdir(self.true_test_dir):
            with open(os.path.join(self.true_test_dir, file), 'r') as open_file:
                is_valid = True
                current = states['root']
                for line in open_file.readlines():
                    if self.syntax_tree.search(line).name not in states:
                        is_valid = False
                        break
                    next_node = states[self.syntax_tree.search(line).name]
                    if matrix[current][next_node] < 1 / 1e10:  # Some small value close to 0
                        is_valid = False
                        break
                    current = next_node
                if is_valid:
                    true_positive += 1

        specificity = true_negative / len(os.listdir(self.false_dir))
        recall = true_positive / len(os.listdir(self.true_test_dir))
        precision = true_positive / (true_positive + (len(os.listdir(self.false_dir)) - true_negative))

        return specificity, recall, precision

    def get_candidates(self, threshold: float = 0.0) -> List[list[int]]:
        """
        Retrieves all candidates based on a threshold.
        :param threshold: The threshold of which candidates can converge from the requirements.
        """
        # Duplicate rows
        candidates = list(map(lambda x: sorted(x), self.find_duplicates(threshold)))
        # Duplicate columns
        candidates += list(map(lambda x: sorted(x), list(
            filter(lambda x: sorted(x) not in candidates, self.find_duplicates(threshold, False)))))
        # Probability of 1
        candidates += list(map(lambda x: sorted(x), list(
            filter(lambda x: sorted(x) not in candidates, self.find_prop_1(threshold)))))

        return candidates

    def compress(self, minimum_size: int, minimum_accuracy: int) -> None:
        """
        Compresses a transition matrix until either the minimum size or minimum accuracy is reached.
        :param minimum_size: The minimum size of the matrix. The transition matrix should not become smaller than this.
        :param minimum_accuracy: The minimum accuracy of the matrix. The transition should not become less accurate than
                                 this.
        """
        assert minimum_size > 0, 'Can not have a size of 0'

        # Training the markov chain using multiprocessing
        self.train()

        previous_matrix = deepcopy(self.transitionMatrix)
        current_accuracy = 1

        while len(self.transitionMatrix) > minimum_size and current_accuracy > minimum_accuracy:
            # Store the current matrix which is known to have the proper requirements
            previous_matrix = deepcopy(self.transitionMatrix)

            # Print the progress of our current compression in the console
            print(str(100 * (self.initial_size - len(self.transitionMatrix)) / (self.initial_size - minimum_size)), '%')

            threshold = 0.0
            candidates = []
            while len(candidates) == 0:  # Search for candidates until some are found
                candidates = self.get_candidates(threshold)
                threshold += 0.001  # Higher threshold in order to find more candidates

            to_split = []
            for c in range(len(candidates)):
                # Split candidates of which we know will make the resulting transition matrix too small.
                if len(candidates[c]) - 1 > len(self.transitionMatrix) - minimum_size:
                    to_split.append(c)
            # We reverse the list to make sure the indexes in to_split do not need to be shifted when deleting from
            # candidates.
            to_split.reverse()
            for s in to_split:
                candidate = candidates[s]
                i = 1
                while i < len(candidate):
                    candidates.append([candidate[i - 1], candidate[i]])
                    i += 1
                del candidates[s]

            # Find the largest candidate (for evaluating the conciseness of a merge)
            self.maxLength = 0
            for c in candidates:
                # The candidates are sorted in order to make sure that the merging of states works properly.
                # The smallest index should be the first element.
                c.sort()
                if len(c) > self.maxLength:
                    self.maxLength = len(c)

            max_index = 0
            # We only want to evaluate the candidates if there are more than 1
            if len(candidates) > 1:
                a_pool = multiprocessing.Pool(processes=12)
                # Evaluate all the candidates using multiprocessing
                results = a_pool.map(self.evaluate_candidate, candidates)
                a_pool.close()
                a_pool.join()

                # Pick the best candidate
                for r in range(len(candidates)):
                    if results[r] > results[max_index]:
                        max_index = r

            self.process_candidate_list(candidates[max_index])
            score = self.calculate_accuracy()
            current_accuracy = np.mean(score)
            if self.eval_file:
                with open(self.eval_file, 'a') as file:
                    file.write('<tr><td>' + str(1 - len(self.transitionMatrix) / self.initial_size) + '</td>')
                    file.write('<td>' + str(score[0]) + '</td>')
                    file.write('<td>' + str(score[1]) + '</td>')
                    file.write('<td>' + str(score[2]) + '</td></tr>\n')

        if len(self.transitionMatrix) < minimum_size or current_accuracy < minimum_accuracy:
            self.transitionMatrix = previous_matrix

    def print_matrix(self, matrix=None):
        """
        Prints the matrix in a human readable format.
        :param matrix: The matrix which to print.
        """
        if matrix is None:
            matrix = self.transitionMatrix
        for r in range(len(matrix)):
            row = str(r) + ": "
            for c in range(len(matrix)):
                row += str(matrix[r][c]) + " "
            print(row)

        [print(i, aaa) for aaa, i in self.states.items()]

    def select_true_traces(self, amount=50):
        """
        Selects random true traces on which the model will be evaluated.
        :param amount: The amount of true traces that should be selected.
        """
        if os.path.exists(self.true_test_dir):
            shutil.rmtree(self.true_test_dir)
        os.mkdir(self.true_test_dir)
        for i in range(amount):
            shutil.copy(os.path.join(self.true_dir, os.listdir(self.true_dir)
                        [random.randint(0, len(os.listdir(self.true_dir)) - 1)]),
                        os.path.join(self.true_test_dir, 'true' + str(i)))


if __name__ == '__main__':
    for j in range(10):
        print('current progress:', j + 1, '/ 10')

        chain = MarkovChain('resources/traces' + str(j + 1) + '/', weight_size=0.5, weight_accuracy=0.5,
                            eval_file='out/eval/evaluation5')
        chain.select_true_traces(100)
        chain.generate_false_traces_from_prefix_tree(100)
        chain.train()
        chain.compress(1, 0)

    # Note that k-cross validation should be used when evaluating for a single size
